ARCHITECTURE: GPT-S
CONTEXT_LEN: 256
DROPOUT: 0.1
QKV_BIAS: false
BATCH_SIZE: 4
NUM_WORKERS: 0
PERSISTENT_WORKERS: false
NUM_EPOCHS: 20
EVAL_ITER: null
MAX_LR: 1.e-3
DIV_FACTOR: 10
FINAL_DIV_FACTOR: 100
THREE_PHASE: True
ANNEAL_STRATEGY: "cos"
CYCLE_MOMENTUM: True
BASE_MOMENTUM: 0.85
MAX_MOMENTUM: 0.95
PCT_START: 0.2
WEIGHT_DECAY: 1.e-2
DECOUPLED_WEIGHT_DECAY: True

ARCHITECTURES:
  GPT-S:
    EMBEDDING_DIM: 768
    NUM_LAYERS: 12
    NUM_HEADS: 12
  GPT-M:
    EMBEDDING_DIM: 1024
    NUM_LAYERS: 24
    NUM_HEADS: 16
  GPT-L:
    EMBEDDING_DIM: 1280
    NUM_LAYERS: 36
    NUM_HEADS: 20
  GPT-XL:
    EMBEDDING_DIM: 1600
    NUM_LAYERS: 48
    NUM_HEADS: 25
